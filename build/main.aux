\relax 
\providecommand{\transparent@use}[1]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Data Types}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Machine Learning Paradigms}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Unsupervised Learning}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Supervised Learning}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Data Preparation/Preprocessing}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Supervised ML, Similarities, kNN \& Performance measurments}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Supervised ML}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Overfitting}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Training and test error}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}kNN}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Distance and similarity measurments}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Finding k}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Performance measures}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}ROC (Receiver Operating Characteristic) curve}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}PRC(Precision-Recall Curve)}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Bias-Varinace tradeoff}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}No free lunch Theorem}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Ockham's Razor}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Error sources and bias-variance tradeoff}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Model selection: Validation score and CV score}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Error Estimate Summary}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Loss minimization (gradient descent)}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Regularization}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Hyperparameter tuning}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Decision Tree, Ensamble Methods \& Random Forest}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Decision Tree}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Pros/Cons}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Ensamble methods}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Bagging}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Boosting}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Comparison}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}Random forest}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.5}Summary Random Forrest}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Probability Recap, Loss Functions, Logistic Regression, Neural Networks Intro}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Probability Basics}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}probability rules}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Designing Loss Functions}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Logistic Regression}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Loss function (Binary Cross Entropy Loss)}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Neural Networks Basics}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.4.1}Number of parameters}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Neural Networks}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Loss function}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Training}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Convolutional Neural Networks (CNN)}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}CNN 1D}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2}CNN 2D}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.3}Pooling}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.4}Transpose Convolution}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Feature Engineering}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Data Peparation and Exploration (EDA)}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Feature Preparation/generation}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Feature selection}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Univariate Feature Selection}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Feature selection using linear models \& regularization}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Text data/Natural Lannguage Processing (NLP)}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.1}Tokenization}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.2}Word Embeddings}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5}Audio data}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1}Linear predictive coding coefficients (LPC)}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.2}Spectogramm - Short Time Fourier Transform}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.3}Mel Frequency Cepstral Coefficients (MFCC)}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Support Vector Machines}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Hyperplanes}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}maximal margin classifier}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Support Vector Classifier SVC}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.1}Handling data that is not linearly separable}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.3.2}Soft margin solution}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Support Vector Machine SVM}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.1}The Kernel Trick}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.2}Kernel Functions}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.3}Primal Form of the SVM}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.4.4}Kernel Trick - Summary}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Gaussian Processes}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Dimensionality Reduction}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}Cluster Analysis}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Gaussian Mixture Models and EM}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}Reinforcement Learning}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14}Generative AI}{12}{}\protected@file@percent }
\gdef \@abspage@last{12}
